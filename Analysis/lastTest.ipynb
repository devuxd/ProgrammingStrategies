{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maryam/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# multinomial_logistic_regression.py\n",
    "# Author : Saimadhu Polamuri\n",
    "# Date: 05-May-2017\n",
    "# About: Multinomial logistic regression model implementation\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    " \n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "%matplotlib inline\n",
    "py.sign_in('marab', 'aVB8eKCue1UMOMzWxkVx')\n",
    " \n",
    "# Dataset Path\n",
    "DATASET_PATH = \"./Input/Debugging.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations ::  27\n",
      "Number of columns ::  3\n",
      "Headers ::  ['Expertise2' 'Guided2' 'Outcome2']\n",
      "Target ::  0     0\n",
      "1     0\n",
      "2     1\n",
      "3     0\n",
      "4     1\n",
      "5     0\n",
      "6     1\n",
      "7     2\n",
      "8     2\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    2\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    2\n",
      "21    0\n",
      "22    0\n",
      "23    2\n",
      "24    0\n",
      "25    1\n",
      "26    0\n",
      "Name: Outcome2, dtype: int64\n",
      "expertise:: [7, 7, 6, 7, 8, 5, 4, 7, 4, 7, 5, 5, 6, 6, 6, 6, 5, 5, 5, 6, 9, 6, 7, 6, 7, 7, 7]\n",
      "Guided:: [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
      "whats this:: ['Expertise2', 'Guided2']\n",
      "[0, 0, 1, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 1, 0]\n",
      "Logistic regression Train Accuracy ::  0.625\n",
      "Logistic regression Test Accuracy ::  1.0\n",
      "Multinomial Logistic regression Train Accuracy ::  0.625\n",
      "Multinomial Logistic regression Test Accuracy ::  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    " \n",
    "def scatter_with_color_dimension_graph(feature, target, layout_labels):\n",
    "    \"\"\"\n",
    "    Scatter with color dimension graph to visualize the density of the\n",
    "    Given feature with target\n",
    "    :param feature:\n",
    "    :param target:\n",
    "    :param layout_labels:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    trace1 = go.Scatter(\n",
    "        y=feature,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size='16',\n",
    "            color=target,\n",
    "            colorscale='Viridis',\n",
    "            showscale=True\n",
    "        )\n",
    "    )\n",
    "    layout = go.Layout(\n",
    "        title=layout_labels[2],\n",
    "        xaxis=dict(title=layout_labels[0]), yaxis=dict(title=layout_labels[1]))\n",
    "    data = [trace1]\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    # plot_url = py.plot(fig)\n",
    "    py.image.save_as(fig, filename=layout_labels[1] + '_Density.png')\n",
    " \n",
    " \n",
    "def create_density_graph(dataset, features_header, target_header):\n",
    "    \"\"\"\n",
    "    Create density graph for each feature with target\n",
    "    :param dataset:\n",
    "    :param features_header:\n",
    "    :param target_header:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for feature_header in features_header:\n",
    "        print \"Creating density graph for feature:: {} \".format(feature_header)\n",
    "        layout_headers = [\"Number of Observation\", feature_header + \" & \" + target_header,\n",
    "                          feature_header + \" & \" + target_header + \" Density Graph\"]\n",
    "        scatter_with_color_dimension_graph(dataset[feature_header], dataset[target_header], layout_headers)\n",
    " \n",
    " \n",
    "def main():\n",
    "    glass_data_headers = [\"Expertise2\",\"Guided2\",\"Outcome2\"]\n",
    "    glass_data = pd.read_csv(DATASET_PATH, names=glass_data_headers)\n",
    " \n",
    "    print \"Number of observations :: \", len(glass_data.index)\n",
    "    print \"Number of columns :: \", len(glass_data.columns)\n",
    "    print \"Headers :: \", glass_data.columns.values\n",
    "    print \"Target :: \", glass_data[glass_data_headers[-1]]\n",
    "#     Train , Test data split\n",
    " \n",
    "#     print \"glass_data_Expertise :: \", list(glass_data[\"Expertise2\"][:0])\n",
    "#     print \"glass_data_target :: \", list(glass_data[\"Outcome2\"][:2])\n",
    "    graph_labels = [\"Number of Observations\", \"expertise & Glass Type\", \"Sample Expertise - Glass Type Density Graph\"]\n",
    "    # scatter_with_color_dimension_graph(list(glass_data[\"RI\"][:10]),\n",
    "    #                                    np.array([1, 1, 1, 2, 2, 3, 4, 5, 6, 7]), graph_labels)\n",
    " \n",
    "    # print \"glass_data_headers[:-1] :: \", glass_data_headers[:-1]\n",
    "    # print \"glass_data_headers[-1] :: \", glass_data_headers[-1]\n",
    "    # create_density_graph(glass_data, glass_data_headers[1:-1], glass_data_headers[-1])\n",
    "    print \"expertise::\" ,list(glass_data[glass_data_headers[0]])\n",
    "    print \"Guided::\", list(glass_data[glass_data_headers[1]])\n",
    "    print \"whats this::\", list(glass_data[glass_data_headers[:-1]])\n",
    "    print list(glass_data[glass_data_headers[-1]])\n",
    "    train_x, test_x, train_y, test_y = train_test_split(glass_data[glass_data_headers[:-2]],\n",
    "                                                        glass_data[glass_data_headers[-1]], train_size=0.9)\n",
    "#     train_x, test_x, train_y, test_y = train_test_split(glass_data[glass_data_headers[:-2]],\n",
    "#                                                         glass_data[glass_data_headers[-1]], train_size=0.9)\n",
    "    # Train multi-classification model with logistic regression\n",
    "    lr = linear_model.LogisticRegression()\n",
    "    lr.fit(train_x, train_y)\n",
    " \n",
    "    # Train multinomial logistic regression model\n",
    "    mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(train_x, train_y)\n",
    " \n",
    "    print \"Logistic regression Train Accuracy :: \", metrics.accuracy_score(train_y, lr.predict(train_x))\n",
    "    print \"Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_y, lr.predict(test_x))\n",
    " \n",
    "    print \"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(train_y, mul_lr.predict(train_x))\n",
    "    print \"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(test_y, mul_lr.predict(test_x))\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maryam/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/Users/maryam/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expertise2</th>\n",
       "      <th>Guided2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.111111</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.250000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Expertise2   Guided2\n",
       "Outcome2                      \n",
       "0           6.111111  0.277778\n",
       "1           6.250000  0.750000\n",
       "2           6.200000  1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "DATASET_PATH = \"./Input/Debugging.txt\"\n",
    "data_headers = [\"Expertise2\",\"Guided2\",\"Outcome2\"]\n",
    "dta = pd.read_csv(DATASET_PATH, names=data_headers)\n",
    "# add \"Outcome2\" column: 1 represents having affairs, 0 represents not\n",
    "dta['Outcome2'] = dta[data_headers[-1]]\n",
    "dta.groupby('Outcome2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Guided2</th>\n",
       "      <th>Outcome2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expertise2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Guided2  Outcome2\n",
       "Expertise2                    \n",
       "4           1.000000  1.500000\n",
       "5           0.666667  0.333333\n",
       "6           0.500000  0.375000\n",
       "7           0.222222  0.333333\n",
       "8           0.000000  1.000000\n",
       "9           1.000000  2.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta.groupby('Expertise2').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Intercept', u'Expertise2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "y, X = dmatrices('Outcome2 ~ Expertise2',\n",
    "                  dta, return_type=\"dataframe\")\n",
    "print X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model = model.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51851851851851849"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>[0.180135020076, -0.245137207404, -0.214524403...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expertise2</td>\n",
       "      <td>[0.0493669437572, -0.196133379204, -0.16453337...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                                                  1\n",
       "0   Intercept  [0.180135020076, -0.245137207404, -0.214524403...\n",
       "1  Expertise2  [0.0493669437572, -0.196133379204, -0.16453337..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the coefficients\n",
    "pd.DataFrame(zip(X.columns, np.transpose(model.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./Input/Debugging.txt\"\n",
    "data_headers = [\"Expertise2\",\"Guided2\",\"Outcome2\"]\n",
    "dta = pd.read_csv(DATASET_PATH, names=data_headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "dta['Guided2'] = dta['Guided2'].astype('str')\n",
    "\n",
    "df = pd.get_dummies(dta,columns=['Guided2'],drop_first = True)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(df[['Expertise2','Guided2_1']],df['Outcome2'])\n",
    "lr.predict(df[['Expertise2','Guided2_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X = df[['Expertise2','Guided2_1']]\n",
    "X = sm.add_constant(X)\n",
    "mod = sm.OLS(df['Outcome2'], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>Outcome2</td>     <th>  R-squared:         </th> <td>   0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 19 Apr 2018</td> <th>  Prob (F-statistic):</th>  <td>0.00201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:01:14</td>     <th>  Log-Likelihood:    </th> <td> -24.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    27</td>      <th>  AIC:               </th> <td>   55.74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    24</td>      <th>  BIC:               </th> <td>   59.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>   -1.0525</td> <td>    0.763</td> <td>   -1.380</td> <td> 0.180</td> <td>   -2.627</td> <td>    0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Expertise2</th> <td>    0.1729</td> <td>    0.114</td> <td>    1.512</td> <td> 0.143</td> <td>   -0.063</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Guided2_1</th>  <td>    1.0549</td> <td>    0.262</td> <td>    4.026</td> <td> 0.000</td> <td>    0.514</td> <td>    1.596</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.285</td> <th>  Durbin-Watson:     </th> <td>   1.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.867</td> <th>  Jarque-Bera (JB):  </th> <td>   0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.205</td> <th>  Prob(JB):          </th> <td>   0.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.734</td> <th>  Cond. No.          </th> <td>    39.9</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               Outcome2   R-squared:                       0.404\n",
       "Model:                            OLS   Adj. R-squared:                  0.354\n",
       "Method:                 Least Squares   F-statistic:                     8.134\n",
       "Date:                Thu, 19 Apr 2018   Prob (F-statistic):            0.00201\n",
       "Time:                        20:01:14   Log-Likelihood:                -24.872\n",
       "No. Observations:                  27   AIC:                             55.74\n",
       "Df Residuals:                      24   BIC:                             59.63\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.0525      0.763     -1.380      0.180      -2.627       0.522\n",
       "Expertise2     0.1729      0.114      1.512      0.143      -0.063       0.409\n",
       "Guided2_1      1.0549      0.262      4.026      0.000       0.514       1.596\n",
       "==============================================================================\n",
       "Omnibus:                        0.285   Durbin-Watson:                   1.644\n",
       "Prob(Omnibus):                  0.867   Jarque-Bera (JB):                0.268\n",
       "Skew:                           0.205   Prob(JB):                        0.875\n",
       "Kurtosis:                       2.734   Cond. No.                         39.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import RegressionResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.identity(len(res.params))\n",
    "A = A[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unbound method wald_test() must be called with RegressionResults instance as first argument (got ndarray instance instead)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-4c0bfa16e6ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRegressionResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwald_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unbound method wald_test() must be called with RegressionResults instance as first argument (got ndarray instance instead)"
     ]
    }
   ],
   "source": [
    "RegressionResults.wald_test(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.05251339,  0.17291415,  1.05493177])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
